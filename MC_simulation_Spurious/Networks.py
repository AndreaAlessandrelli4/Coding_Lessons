import numpy as np
import tensorflow as tf
from tqdm import tqdm


# function to generate a tensor of patterns
# INPUT:
# steps = "number of parallel MC simulations you want to carry out", N = "length of each pattern", K = "number of patterns"
# OUTPUT:
# a Radeemacher {-1,+1} tf tensor of dimension "steps" x "K" x "N"
def gen_patterns(steps, N, K):
    ξ = 2*np.random.randint(0,2,(steps,K,N))-1
    return tf.convert_to_tensor(ξ,dtype=tf.float32)


# function to generate a tensor of Hebbian Synaptic Matrix
# INPUT:
# ξ = "the tensor generated by gen_patterns(), so a tf  Radeemacher {-1,+1} tf tensor of dimension "steps" x "K" x "N" "
# OUTPUT:
# a tf tensor of dimension "steps" x "N" x "N" wich has for each steps dim a Hebbian N x N synaptic matix
def Hebb_J(ξ):
    N = np.shape(ξ)[-1]
    return tf.einsum('aki,akj->aij', ξ, ξ) / N


# MC simulations for standard Hopfield Network
class Hopfield_Network:
    def __init__(self):
        self.steps = None; self.N = None; self.K = None; self.Ξ = None; self.J = None; self.σ = None; self.σ0 = None
    
    
    # inizialization of the variable and generation of the synaptic matrix
    def prepare(self, steps_input, N_input, K_input):
        self.steps = steps_input
        self.N = N_input
        self.K = K_input
        self.Ξ = gen_patterns(self.steps, self.N, self.K)
        self.J = Hebb_J(self.Ξ)

    # MC simulations
    def dynamics(self, mu, r, β, loop, updates, mode="parallel", verbose = True):
        N = self.N; K = self.K; sΞ= self.Ξ; J = self.J; steps= self.steps
        χ = np.random.choice([1, -1], size=(loop, N), p=[(1+r)/2, (1-r)/2])
        σ0 = sΞ[:,mu,:]
        σ = np.einsum('bj,aj->abj',χ , σ0)
        self.σ0 = np.copy(σ)
        if verbose:
            disable = False
        else:
            disable = True

        # parallel updating
        if mode == "parallel":
            σ=tf.convert_to_tensor(σ,dtype=tf.float32)
            for _ in tqdm(range(0,updates), disable=disable):
                h = tf.einsum('Aij,Abj->Abi',J,σ)
                u = np.random.uniform(-1,1,(steps, loop, N))
                σ = tf.sign(tf.tanh(β * h) + u)
                self.σ = np.copy(σ)

        # serial updating
        elif mode == "serial":
            for _ in tqdm(range(0,updates*N), disable=disable):
                idx = np.random.choice(N, size=(steps, loop))
                h = np.einsum('Aij,Abj->Abi',J,σ)
                u = np.random.uniform(-1,1,(steps, loop, N))
                for ids,s in enumerate(range(steps)):
                    for idl, l in enumerate(range(loop)):
                        σ[ids, idl, idx[ids, idl]] = np.sign(np.tanh(β * h) + u)[ids, idl, idx[ids, idl]]
                self.σ = σ



# MC simulations for TAM Network
class TAM_Network:
    def __init__(self):
        self.N = None; self.K = None; self.Ξ=None; self.L = None; self.σ = None; self.σ0 = None; self.Ω = []
        
    # inizialization of the variable and generation of the synaptic matrix
    def prepare(self, steps_input, N_input, K_input, L_input):
        self.steps = steps_input
        self.N = N_input
        self.K = K_input
        self.Ξ = gen_patterns(self.steps, self.N, self.K)
        self.L = L_input
        
    # computation of the internal fields
    def compute_fields(self, input_field, σ, P):
        J = self.Ξ; N = self.N; L = self.L
        M = tf.einsum('Ski, Sli->Slk', J, σ)/N
        h1 = tf.einsum('Ski, Slk->Sli', J, M)
        h2_1 = tf.einsum('Sak, Sbk-> Sak', M**(P/2-1), M**(P/2))
        h2_2 = tf.einsum('Sak, Sak-> Sak', M**(P/2-1), M**(P/2))
        h2 = tf.einsum('Ski, Sak-> Sai', J, h2_1 - h2_2)
        h3 = input_field
        return [h1,h2, h3]

    def dynamics(self, P, β, λ, h, updates, verbose = True):
        N = self.N; K = self.K; J= self.Ξ; steps= self.steps; L = self.L
        s = np.shape(J)[0]
        part_input = np.array([J[:,i,:] for i in range(L)])
        σ = np.einsum('sli, si->sli',np.ones((s,L,N)),tf.sign(np.sum(part_input, axis = 0)))
        
        h_input = np.copy(σ)
        self.σ0 = np.copy(σ)
        self.Ω.append(np.einsum('sli,ski->slk',σ, J)/N)
        σ=tf.convert_to_tensor(σ,dtype=tf.float32)
        
        if verbose:
            disable = False
        else:
            disable = True
            
        for _ in tqdm(range(updates), disable=disable):
            h1, h2, h3 = self.compute_fields(h_input, σ, P)
            ht = h1 - λ * h2 + h * h3
            u = np.random.uniform(-1,1,(s,L,N))
            ht=tf.convert_to_tensor(ht,dtype=tf.float32)
            u=tf.convert_to_tensor(u,dtype=tf.float32)
            σ = tf.sign(tf.tanh(β * ht) + u)
            self.Ω.append(np.einsum('sli,ski->slk',σ, J)/N)
            
        self.σ = σ
        self.Ω = np.array(self.Ω)
